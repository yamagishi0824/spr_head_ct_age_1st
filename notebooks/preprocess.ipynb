{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "533269fc",
   "metadata": {
    "papermill": {
     "duration": 27.718617,
     "end_time": "2024-04-27T13:14:13.382170",
     "exception": false,
     "start_time": "2024-04-27T13:13:45.663553",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pydicom\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "from scipy.ndimage import zoom\n",
    "import PIL.Image as Image\n",
    "import cv2\n",
    "import shutil\n",
    "\n",
    "img_size = 512\n",
    "slice_num = 128\n",
    "\n",
    "def window_image(dcm, window_center, window_width, intercept, slope, rescale=True):\n",
    "    img = dcm.pixel_array\n",
    "    img = (img * slope + intercept)\n",
    "    img_min = window_center - window_width // 2\n",
    "    img_max = window_center + window_width // 2\n",
    "    img[img < img_min] = img_min\n",
    "    img[img > img_max] = img_max\n",
    "    if rescale:\n",
    "        img = (img - img_min) / (img_max - img_min)\n",
    "        # img = (img * 255).astype(np.uint8)\n",
    "    return img\n",
    "\n",
    "def no_window_image(dcm, intercept, slope, rescale=True):\n",
    "    img = dcm.pixel_array\n",
    "    img = (img * slope + intercept)\n",
    "    if rescale:\n",
    "        img = (img - np.min(img)) / (np.max(img) - np.min(img))\n",
    "        # img = (img * 255).astype(np.uint8)\n",
    "    return img\n",
    "\n",
    "def window_volume(volume, window_center, window_width, rescale=True):\n",
    "    img = volume\n",
    "    img_min = window_center - window_width // 2\n",
    "    img_max = window_center + window_width // 2\n",
    "    img[img < img_min] = img_min\n",
    "    img[img > img_max] = img_max\n",
    "    if rescale:\n",
    "        img = (img - img_min) / (img_max - img_min)\n",
    "        # img = (img * 255).astype(np.uint8)\n",
    "    return img\n",
    "\n",
    "def normalize_image(image):\n",
    "    image = image - np.min(image)\n",
    "    return image / np.max(image)\n",
    "\n",
    "def resize_volume(volume, target_shape=(slice_num, img_size, img_size)):\n",
    "    original_shape = np.array(volume.shape)\n",
    "    target_shape = np.array(target_shape)\n",
    "    scale_factors = target_shape / original_shape\n",
    "    resized_volume = zoom(volume, scale_factors, order=3)  # order=3 は三次元補間（三次スプライン補間）\n",
    "    \n",
    "    return resized_volume\n",
    "\n",
    "def sort_dicoms_by_position(dicom_files):\n",
    "    dicoms = [pydicom.dcmread(df, force=True) for df in dicom_files]\n",
    "    dicoms.sort(key=lambda x: float(x.ImagePositionPatient[2]))\n",
    "    return dicoms\n",
    "\n",
    "def create_npy_in_memory(dicom_files, window_center=None, window_width=None):\n",
    "    dicoms = sort_dicoms_by_position(dicom_files)\n",
    "    #volume = np.stack([no_window_image(dcm, dcm.RescaleIntercept, dcm.RescaleSlope, False) if window_center is not None and window_width is not None else dcm.pixel_array for dcm in dicoms])\n",
    "    try:\n",
    "        volume = np.stack([no_window_image(dcm, dcm.RescaleIntercept, dcm.RescaleSlope, False) if window_center is not None and window_width is not None else dcm.pixel_array for dcm in dicoms])\n",
    "    except:\n",
    "        volume = np.stack([cv2.resize(no_window_image(dcm, dcm.RescaleIntercept, dcm.RescaleSlope, False), (img_size, img_size)) if window_center is not None and window_width is not None else dcm.pixel_array for dcm in dicoms])\n",
    "        print(dicom_files[0])\n",
    "    for i, dcm in enumerate(dicoms):\n",
    "        if dcm.PhotometricInterpretation == \"MONOCHROME1\":\n",
    "            volume[i] = np.invert(volume[i])\n",
    "    # volume = resize_volume(volume)\n",
    "    volume_brain = window_volume(volume.copy(), 40, 80)\n",
    "    volume_bone = window_volume(volume.copy(), 600, 2800)\n",
    "    volume_soft = window_volume(volume.copy(), 60, 400)\n",
    "    volume = np.stack([volume_brain, volume_bone, volume_soft]) * 255\n",
    "    volume = volume.astype(np.uint8)\n",
    "    return volume\n",
    "\n",
    "def save_volume_to_zip(volume, accession_number, zip_file):\n",
    "    with zip_file.open(accession_number + '.npy', 'w') as file_handle:\n",
    "        np.save(file_handle, volume)\n",
    "        \n",
    "def save_slice_as_png_zip(volume, accession_number, zip_file):\n",
    "    for i in range(volume.shape[1]):  # Loop over slices\n",
    "        slice_img = volume[:,i,:,:]\n",
    "        slice_img = slice_img.transpose(1,2,0)\n",
    "        img = Image.fromarray(slice_img)\n",
    "        img = img.convert(\"RGB\")  # Convert to RGB for saving as PNG\n",
    "        with zip_file.open(f\"{accession_number}_slice_{i}.png\", 'w') as file_handle:\n",
    "            img.save(file_handle, format=\"PNG\")\n",
    "\n",
    "def save_slice_as_png(volume, accession_number):\n",
    "    save_dir_tmp = os.path.join(output_base_dir, accession_number)\n",
    "    os.makedirs(save_dir_tmp, exist_ok=True)\n",
    "    for i in range(volume.shape[1]):  # Loop over slices\n",
    "        slice_img = volume[:,i,:,:]\n",
    "        slice_img = slice_img.transpose(1,2,0)\n",
    "        slice_img = cv2.resize(slice_img, (img_size, img_size))\n",
    "        save_path = os.path.join(save_dir_tmp, f\"slice_{i}.png\")\n",
    "        cv2.imwrite(save_path, slice_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0715bd08",
   "metadata": {},
   "source": [
    "### convert train data to stacked png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4c15c0",
   "metadata": {
    "papermill": {
     "duration": 0.012907,
     "end_time": "2024-04-27T13:14:13.397727",
     "exception": false,
     "start_time": "2024-04-27T13:14:13.384820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_dir = \"../data/dataset_jpr_train/dataset_jpr_train\"\n",
    "output_base_dir = f\"../data/train_stacked_{img_size}\"\n",
    "zip_path = os.path.join(output_base_dir, 'npy_files.zip')\n",
    "os.makedirs(output_base_dir, exist_ok=True)\n",
    "\n",
    "roots = [\"1\", \"2\", \"3\"]\n",
    "for root_dir in roots:\n",
    "    root_path = os.path.join(base_dir, root_dir)\n",
    "    for accession_number in tqdm(os.listdir(root_path)):\n",
    "        accession_path = os.path.join(root_path, accession_number)\n",
    "        dicom_files = [os.path.join(accession_path, f) for f in os.listdir(accession_path)]\n",
    "        try:\n",
    "            volume = create_npy_in_memory(dicom_files, window_center=40, window_width=80)\n",
    "            save_slice_as_png(volume, accession_number)\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR processing volume in {accession_path}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26663729",
   "metadata": {},
   "source": [
    "### convert test data to stacked png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e495a31",
   "metadata": {
    "papermill": {
     "duration": 0.002362,
     "end_time": "2024-04-27T13:14:13.402885",
     "exception": false,
     "start_time": "2024-04-27T13:14:13.400523",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_dir = \"../data/dataset_jpr_test2\"\n",
    "output_base_dir = f\"../data/test_stacked_{img_size}\" #\"/kaggle/working/3d_numpy_files/\"\n",
    "os.makedirs(output_base_dir, exist_ok=True)\n",
    "roots = [\"dataset_jpr_test2\"]\n",
    "for root_dir in roots:\n",
    "    root_path = os.path.join(base_dir, root_dir)\n",
    "    for accession_number in tqdm(os.listdir(root_path)):\n",
    "        accession_path = os.path.join(root_path, accession_number)\n",
    "        dicom_files = [os.path.join(accession_path, f) for f in os.listdir(accession_path)]\n",
    "        try:\n",
    "            volume = create_npy_in_memory(dicom_files, window_center=40, window_width=80)\n",
    "            # save_volume_to_zip(volume, accession_number, zip_file)\n",
    "            save_slice_as_png(volume, accession_number)\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR processing volume in {accession_path}: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8208918,
     "sourceId": 71447,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30664,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 44.379046,
   "end_time": "2024-04-27T13:14:13.825753",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-27T13:13:29.446707",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
